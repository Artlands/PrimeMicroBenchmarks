{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIKWID Profile Parser\n",
    "\n",
    "Parse LIKWID `.prof` files in `tests/SPEChpc/IntelSPR/job-submit/{2.5GHz, DVFS, ondemand}/profiles`,\n",
    "aggregate metrics across sockets, and plot a selected field.\n",
    "\n",
    "Copy the notebook to each folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d217eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User inputs\n",
    "benchmark_name = 'hpgmgfv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a38152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "SUM_FIELDS = {\n",
    "    'Energy [J]',\n",
    "    'Power [W]',\n",
    "    'Energy PP0 [J]',\n",
    "    'Power PP0 [W]',\n",
    "    'Energy DRAM [J]',\n",
    "    'Power DRAM [W]',\n",
    "    'Energy PLATFORM [J]',\n",
    "    'Power PLATFORM [W]',\n",
    "    'Memory read bandwidth [MBytes/s]',\n",
    "    'Memory read data volume [GBytes]',\n",
    "    'Memory write bandwidth [MBytes/s]',\n",
    "    'Memory write data volume [GBytes]',\n",
    "    'Memory bandwidth [MBytes/s]',\n",
    "    'Memory data volume [GBytes]',\n",
    "    'L3 request rate',\n",
    "    'L3 miss rate',\n",
    "    'L3 miss ratio',\n",
    "}\n",
    "\n",
    "\n",
    "def find_dvfs_dir(start: Path) -> Path:\n",
    "    current = start.resolve()\n",
    "    for _ in range(6):\n",
    "        if (current / 'profiles').is_dir():\n",
    "            return current\n",
    "        if current.parent == current:\n",
    "            break\n",
    "        current = current.parent\n",
    "    raise FileNotFoundError('Could not find a folder containing profiles/.')\n",
    "\n",
    "\n",
    "def extract_job_id(path: Path | str) -> str:\n",
    "    name = path.name if isinstance(path, Path) else Path(path).name\n",
    "    parts = name.split('.')\n",
    "    if len(parts) < 3:\n",
    "        raise ValueError(f'Could not infer job id from {name}')\n",
    "    return parts[-2]\n",
    "\n",
    "\n",
    "def _stdout_candidates(folder: Path, job_id: str) -> List[Path]:\n",
    "    pattern = f'*.{job_id}.out'\n",
    "    matches = sorted(folder.rglob(pattern))\n",
    "    return [\n",
    "        path\n",
    "        for path in matches\n",
    "        if 'timeline' not in path.name and not path.name.startswith('likwid_')\n",
    "    ]\n",
    "\n",
    "\n",
    "def find_stdout_for_job(dvfs_dir: Path, job_id: str) -> Path:\n",
    "    search_roots = [dvfs_dir, dvfs_dir.parent]\n",
    "    candidates: List[Path] = []\n",
    "    for root in search_roots:\n",
    "        if root.exists():\n",
    "            candidates.extend(_stdout_candidates(root, job_id))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f'No stdout file found for job {job_id} under {dvfs_dir.parent}')\n",
    "    candidates = sorted(candidates)\n",
    "    if len(candidates) > 1:\n",
    "        print(f'Multiple stdout candidates found; using {candidates[0]}')\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def parse_headers(stdout_path: Path) -> List[Sequence[str]]:\n",
    "    headers: List[Sequence[str]] = []\n",
    "    with stdout_path.open() as handle:\n",
    "        for line in handle:\n",
    "            if line.startswith('# GID|'):\n",
    "                parts = line.lstrip('#').strip().split('|')\n",
    "                fields = parts[3:]\n",
    "                if fields:\n",
    "                    headers.append(fields)\n",
    "    if not headers:\n",
    "        raise RuntimeError(f'No LIKWID headers found in {stdout_path}')\n",
    "    return headers\n",
    "\n",
    "\n",
    "def aggregate_metric(values: Sequence[float], field: str) -> float:\n",
    "    if not values:\n",
    "        raise KeyError(f'Missing values for field {field}')\n",
    "    if field in SUM_FIELDS:\n",
    "        return float(sum(values))\n",
    "    return float(sum(values) / len(values))\n",
    "\n",
    "\n",
    "def load_likwid_profile(profile_path: Path, stdout_path: Path, *, skip_initial: int = 0) -> pd.DataFrame:\n",
    "    headers = parse_headers(stdout_path)\n",
    "    if len(headers) > 1:\n",
    "        print(f'Warning: expected 1 header set, found {len(headers)} in {stdout_path.name}')\n",
    "    header = headers[0]\n",
    "    global_field = header[0]\n",
    "    metric_fields = header[1:]\n",
    "\n",
    "    rows: List[Dict[str, float]] = []\n",
    "    with profile_path.open() as handle:\n",
    "        for raw_line in handle:\n",
    "            line = raw_line.strip()\n",
    "            if not line or not line[0].isdigit():\n",
    "                continue\n",
    "            parts = line.split(',')\n",
    "            if len(parts) < 4:\n",
    "                continue\n",
    "            gid = int(parts[0])\n",
    "            metrics_count = int(parts[1])\n",
    "            cpu_count = int(parts[2])\n",
    "            values = [float(val) for val in parts[3:]]\n",
    "\n",
    "            if metrics_count != len(metric_fields):\n",
    "                raise ValueError(\n",
    "                    f'Header mismatch: expected {len(metric_fields)} metrics, got {metrics_count} in {profile_path.name}'\n",
    "                )\n",
    "\n",
    "            expected_values = 1 + metrics_count * cpu_count\n",
    "            if len(values) != expected_values:\n",
    "                raise ValueError(\n",
    "                    f'Expected {expected_values} numeric entries, got {len(values)} in {profile_path.name}'\n",
    "                )\n",
    "\n",
    "            global_value = values[0]\n",
    "            metric_values = values[1:]\n",
    "\n",
    "            extracted: Dict[str, float] = {global_field: global_value}\n",
    "            for idx, field in enumerate(metric_fields):\n",
    "                start = idx * cpu_count\n",
    "                end = start + cpu_count\n",
    "                segment = metric_values[start:end]\n",
    "                if not segment:\n",
    "                    continue\n",
    "                extracted[field] = aggregate_metric(segment, field)\n",
    "\n",
    "            extracted['gid'] = gid\n",
    "            rows.append(extracted)\n",
    "\n",
    "    if not rows:\n",
    "        raise RuntimeError(f'No LIKWID samples parsed from {profile_path.name}')\n",
    "\n",
    "    if skip_initial:\n",
    "        rows = rows[skip_initial:]\n",
    "\n",
    "    df = pd.DataFrame(rows).reset_index(drop=True)\n",
    "    df.index.name = 'sample_index'\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_metric(df: pd.DataFrame, metric_to_plot: str, *, y_limits: tuple[float, float] | None = None) -> None:\n",
    "    if metric_to_plot not in df.columns:\n",
    "        raise ValueError(f\"Metric '{metric_to_plot}' not found. Choose one of: {sorted(df.columns)}\")\n",
    "\n",
    "    time_axis = df['Total runtime [s]'] if 'Total runtime [s]' in df.columns else df.index\n",
    "    time_label = 'Total runtime [s]' if 'Total runtime [s]' in df.columns else 'Sample index'\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(time_axis, df[metric_to_plot], marker='')\n",
    "    plt.xlabel(time_label)\n",
    "    plt.ylabel(metric_to_plot)\n",
    "    plt.title(f'{metric_to_plot} across LIKWID samples')\n",
    "    if y_limits is not None:\n",
    "        plt.ylim(*y_limits)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeba704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect the DVFS-style folder by looking for profiles/ above the notebook location.\n",
    "dvfs_dir = find_dvfs_dir(Path.cwd())\n",
    "profiles_dir = dvfs_dir / 'profiles'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f032e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available profiles and select the newest one for the benchmark.\n",
    "profile_paths = sorted(profiles_dir.glob('spechpc_*.prof'))\n",
    "profile_table = []\n",
    "for path in profile_paths:\n",
    "    parts = path.stem.split('.')\n",
    "    name = parts[0].removeprefix('spechpc_')\n",
    "    job = parts[1] if len(parts) > 1 else ''\n",
    "    profile_table.append({'benchmark': name, 'job_id': job, 'path': path})\n",
    "\n",
    "profiles_df = pd.DataFrame(profile_table).sort_values(['benchmark', 'job_id'])\n",
    "profiles_df\n",
    "\n",
    "match = profiles_df[profiles_df['benchmark'] == benchmark_name]\n",
    "if match.empty:\n",
    "    raise ValueError(f'No profiles found for benchmark {benchmark_name}')\n",
    "\n",
    "match = match.sort_values('job_id')\n",
    "profile_file = Path(match.iloc[-1]['path'])\n",
    "job_id = extract_job_id(profile_file)\n",
    "stdout_file = find_stdout_for_job(dvfs_dir, job_id)\n",
    "\n",
    "print('Selected profile:', profile_file)\n",
    "print('Stdout:', stdout_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_initial = 3  # drop the first N samples if they are noisy\n",
    "df = load_likwid_profile(profile_file, stdout_file, skip_initial=skip_initial)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtime, average power, energy, and EDP\n",
    "required_fields = [\n",
    "    'Power [W]',\n",
    "    'Power DRAM [W]',\n",
    "    'Power PLATFORM [W]',\n",
    "]\n",
    "missing = [field for field in required_fields if field not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns for power/energy calculations: {missing}\")\n",
    "\n",
    "if 'Total runtime [s]' in df.columns:\n",
    "    time_axis = df['Total runtime [s]']\n",
    "    total_runtime = float(time_axis.iloc[-1])\n",
    "else:\n",
    "    time_axis = df.index\n",
    "    total_runtime = float(time_axis[-1] - time_axis[0]) if len(time_axis) > 1 else 0.0\n",
    "\n",
    "time_values = time_axis.to_numpy()\n",
    "cpu_power = df['Power [W]'].to_numpy()\n",
    "dram_power = df['Power DRAM [W]'].to_numpy()\n",
    "platform_power = df['Power PLATFORM [W]'].to_numpy()\n",
    "\n",
    "avg_cpu_power = float(df['Power [W]'].mean())\n",
    "avg_dram_power = float(df['Power DRAM [W]'].mean())\n",
    "avg_platform_power = float(df['Power PLATFORM [W]'].mean())\n",
    "avg_total_power = avg_cpu_power + avg_dram_power + avg_platform_power\n",
    "\n",
    "if len(time_values) > 1:\n",
    "    dt = time_values[1:] - time_values[:-1]\n",
    "    total_cpu_energy = float((cpu_power[:-1] + cpu_power[1:]).dot(dt) / 2.0)\n",
    "    total_dram_energy = float((dram_power[:-1] + dram_power[1:]).dot(dt) / 2.0)\n",
    "    total_platform_energy = float((platform_power[:-1] + platform_power[1:]).dot(dt) / 2.0)\n",
    "else:\n",
    "    total_cpu_energy = 0.0\n",
    "    total_dram_energy = 0.0\n",
    "    total_platform_energy = 0.0\n",
    "\n",
    "total_energy = total_cpu_energy + total_dram_energy + total_platform_energy\n",
    "edp = total_energy * total_runtime\n",
    "\n",
    "print(f'Total runtime [s]: {total_runtime:.3f}')\n",
    "print(f'Average CPU Power [W]: {avg_cpu_power:.3f}')\n",
    "print(f'Average DRAM power [W]: {avg_dram_power:.3f}')\n",
    "print(f'Average Power PLATFORM [W]: {avg_platform_power:.3f}')\n",
    "print(f'Average total power [W]: {avg_total_power:.3f}')\n",
    "print(f'Total CPU energy [J]: {total_cpu_energy:.3f}')\n",
    "print(f'Total DRAM energy [J]: {total_dram_energy:.3f}')\n",
    "print(f'Total PLATFORM energy [J]: {total_platform_energy:.3f}')\n",
    "print(f'Total energy [J]: {total_energy:.3f}')\n",
    "print(f'EDP [J*s]: {edp:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = 'Power [W]'\n",
    "plot_metric(df, metric_to_plot, y_limits=(0, 600))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a52c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Power DRAM [W]\"\n",
    "plot_metric(df, metric_to_plot, y_limits=(0, 120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8549e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_to_plot = \"Clock [MHz]\"\n",
    "plot_metric(df, metric_to_plot, y_limits=(0, 2600))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
