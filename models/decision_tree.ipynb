{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d977c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0d72c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d12e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    HighFreq       0.99      1.00      0.99      1618\n",
      "     LowFreq       0.99      0.99      0.99       945\n",
      "     MedFreq       1.00      1.00      1.00       601\n",
      "\n",
      "    accuracy                           0.99      3164\n",
      "   macro avg       0.99      0.99      0.99      3164\n",
      "weighted avg       0.99      0.99      0.99      3164\n",
      "\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[1610    8    0]\n",
      " [  12  933    0]\n",
      " [   0    0  601]]\n",
      "\n",
      "=== Feature Importances ===\n",
      "                  feature  importance\n",
      "2             Stall_Ratio    0.411494\n",
      "1          Math_Intensity    0.353368\n",
      "0                     CPI    0.218385\n",
      "6             Clock_Ratio    0.010753\n",
      "3  System_BW_Proxy [GB/s]    0.005999\n",
      "4             Branch_MPKI    0.000000\n",
      "5           GFLOPS_Approx    0.000000\n",
      "\n",
      "=== C-Code Logic (Copy this to your Daemon) ===\n",
      "|--- Math_Intensity <= 0.08\n",
      "|   |--- CPI <= 0.88\n",
      "|   |   |--- System_BW_Proxy [GB/s] <= 0.00\n",
      "|   |   |   |--- CPI <= 0.35\n",
      "|   |   |   |   |--- class: HighFreq\n",
      "|   |   |   |--- CPI >  0.35\n",
      "|   |   |   |   |--- class: LowFreq\n",
      "|   |   |--- System_BW_Proxy [GB/s] >  0.00\n",
      "|   |   |   |--- System_BW_Proxy [GB/s] <= 0.00\n",
      "|   |   |   |   |--- CPI <= 0.39\n",
      "|   |   |   |   |   |--- class: LowFreq\n",
      "|   |   |   |   |--- CPI >  0.39\n",
      "|   |   |   |   |   |--- class: HighFreq\n",
      "|   |   |   |--- System_BW_Proxy [GB/s] >  0.00\n",
      "|   |   |   |   |--- System_BW_Proxy [GB/s] <= 0.00\n",
      "|   |   |   |   |   |--- class: LowFreq\n",
      "|   |   |   |   |--- System_BW_Proxy [GB/s] >  0.00\n",
      "|   |   |   |   |   |--- class: LowFreq\n",
      "|   |--- CPI >  0.88\n",
      "|   |   |--- Stall_Ratio <= 0.52\n",
      "|   |   |   |--- Clock_Ratio <= 1.00\n",
      "|   |   |   |   |--- System_BW_Proxy [GB/s] <= 1.04\n",
      "|   |   |   |   |   |--- class: HighFreq\n",
      "|   |   |   |   |--- System_BW_Proxy [GB/s] >  1.04\n",
      "|   |   |   |   |   |--- class: LowFreq\n",
      "|   |   |   |--- Clock_Ratio >  1.00\n",
      "|   |   |   |   |--- CPI <= 64.03\n",
      "|   |   |   |   |   |--- class: LowFreq\n",
      "|   |   |   |   |--- CPI >  64.03\n",
      "|   |   |   |   |   |--- class: HighFreq\n",
      "|   |   |--- Stall_Ratio >  0.52\n",
      "|   |   |   |--- class: LowFreq\n",
      "|--- Math_Intensity >  0.08\n",
      "|   |--- Stall_Ratio <= 0.05\n",
      "|   |   |--- class: HighFreq\n",
      "|   |--- Stall_Ratio >  0.05\n",
      "|   |   |--- Stall_Ratio <= 0.09\n",
      "|   |   |   |--- class: MedFreq\n",
      "|   |   |--- Stall_Ratio >  0.09\n",
      "|   |   |   |--- class: MedFreq\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Load Data\n",
    "# Assuming CSV format: label,CPI,Math_Intensity,Stall_Ratio,System_BW_Proxy,Branch_MPKI,GFLOPS_Approx,Clock_Ratio\n",
    "df = pd.read_csv('../scripts/csv/training_dataset_dvfs_all.csv')\n",
    "\n",
    "# 2. Data Cleaning\n",
    "# Remove rows with NaN or infinite values (common in Likwid startup/shutdown)\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 3. Feature Selection\n",
    "# We separate the target (y) from the features (X)\n",
    "features = ['CPI', 'Math_Intensity', 'Stall_Ratio', 'System_BW_Proxy [GB/s]', \n",
    "            'Branch_MPKI', 'GFLOPS_Approx', 'Clock_Ratio']\n",
    "\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "# 4. Split Data (Stratified)\n",
    "# Stratify ensures we get a mix of Compute/Memory/Spin in both train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 5. Model Training (Decision Tree)\n",
    "# max_depth=5 keeps the logic simple enough to code manually in C later\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=42, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 6. Evaluation\n",
    "print(\"=== Classification Report ===\")\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 7. Feature Importance Analysis\n",
    "# This tells you which counters are actually driving the decisions\n",
    "importances = pd.DataFrame({'feature': features, 'importance': clf.feature_importances_})\n",
    "print(\"\\n=== Feature Importances ===\")\n",
    "print(importances.sort_values(by='importance', ascending=False))\n",
    "\n",
    "# 8. Export Logic for C/C++\n",
    "print(\"\\n=== C-Code Logic (Copy this to your Daemon) ===\")\n",
    "tree_rules = export_text(clf, feature_names=features)\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f7fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated ../ctrl/model.c\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import _tree\n",
    "import numpy as np\n",
    "\n",
    "def generate_model_c_file(clf, feature_names, filename=\"../dvfs/model.c\"):\n",
    "    tree_ = clf.tree_\n",
    "    \n",
    "    # Mapping: Ensure these keys match your training labels exactly!\n",
    "    label_to_enum = {\n",
    "        \"LowFreq\":  \"FREQ_LEVEL_LOW\",\n",
    "        \"MedFreq\":  \"FREQ_LEVEL_MED\",\n",
    "        \"HighFreq\": \"FREQ_LEVEL_HIGH\"\n",
    "    }\n",
    "    \n",
    "    model_classes = list(clf.classes_)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        # Write Includes\n",
    "        f.write(\"/* Auto-generated by Python ML Exporter */\\n\")\n",
    "        f.write(\"#include \\\"model.h\\\"\\n\")\n",
    "        f.write(\"#include <stdlib.h>\\n\\n\")\n",
    "        \n",
    "        # Write Function Signature\n",
    "        f.write(\"FreqLevel predict_phase_level(double CPI, double Math_Intensity, double Stall_Ratio, double System_BW_Proxy, double Branch_MPKI, double GFLOPS_Approx, double Clock_Ratio) {\\n\")\n",
    "\n",
    "        # Recursive Tree Walker\n",
    "        def recurse(node, depth):\n",
    "            indent = \"    \" * depth\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                # Decision Node\n",
    "                feat_name = feature_names[tree_.feature[node]]\n",
    "                threshold = tree_.threshold[node]\n",
    "                f.write(f\"{indent}if ({feat_name} <= {threshold:.6f}) {{\\n\")\n",
    "                recurse(tree_.children_left[node], depth + 1)\n",
    "                f.write(f\"{indent}}} else {{\\n\")\n",
    "                recurse(tree_.children_right[node], depth + 1)\n",
    "                f.write(f\"{indent}}}\\n\")\n",
    "            else:\n",
    "                # Leaf Node\n",
    "                class_idx = np.argmax(tree_.value[node])\n",
    "                label_str = model_classes[class_idx]\n",
    "                enum_val = label_to_enum.get(label_str, \"FREQ_LEVEL_HIGH\") # Default fallback\n",
    "                \n",
    "                f.write(f\"{indent}// Prediction: {label_str}\\n\")\n",
    "                f.write(f\"{indent}return {enum_val};\\n\")\n",
    "\n",
    "        # Start Recursion\n",
    "        recurse(0, 1)\n",
    "        \n",
    "        # Close Function\n",
    "        f.write(\"}\\n\")\n",
    "    \n",
    "    print(f\"Successfully generated {filename}\")\n",
    "\n",
    "# --- USAGE EXAMPLE ---\n",
    "# Assuming 'clf' is your trained DecisionTreeClassifier\n",
    "features = ['CPI', 'Math_Intensity', 'Stall_Ratio', 'System_BW_Proxy', \n",
    "            'Branch_MPKI', 'GFLOPS_Approx', 'Clock_Ratio']\n",
    "\n",
    "generate_model_c_file(clf, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
