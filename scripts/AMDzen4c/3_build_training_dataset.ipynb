{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build training dataset (DVFS 2.25GHz)\n",
    "\n",
    "This notebook extracts loop-only profiling samples from `apps/<benchmark>/` and writes a labeled CSV.\n",
    "Labels follow the DVFS guidance groups: HighFreq, MedFreq, LowFreq.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e734985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Sequence\n",
    "import csv\n",
    "\n",
    "FEATURE_FIELDS = [\n",
    "    'CPI',\n",
    "    'Math_Intensity',\n",
    "    'Stall_Ratio',\n",
    "    'System_BW_Proxy',\n",
    "    'Branch_MPKI',\n",
    "    'GFLOPS_Approx',\n",
    "    'Clock_Ratio',\n",
    "]\n",
    "\n",
    "# LABELS = {\n",
    "#     'HighFreq': {\n",
    "#         'atomic_fight',\n",
    "#         'branch_mispredict',\n",
    "#         'dgemm',\n",
    "#         'fft_mix',\n",
    "#         'icache_thrash',\n",
    "#         'tree_walk',\n",
    "#     },\n",
    "#     'MedFreq': {\n",
    "#         'l3_stencil',\n",
    "#         'spmv',\n",
    "#         'stream',\n",
    "#     },\n",
    "#     'LowFreq': {\n",
    "#         'io_write',\n",
    "#         'mpi_bandwidth',\n",
    "#         'mpi_barrier',\n",
    "#         'pointer_chase',\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# Replace these two label sets with the outputs from process_apps.ipynb\n",
    "LABELS_ENERGY = {\n",
    "    'HighFreq': {\n",
    "        'atomic_fight',\n",
    "        'branch_mispredict',\n",
    "        'dgemm',\n",
    "        'fft_mix',\n",
    "        'io_write',\n",
    "        'l3_stencil'\n",
    "    },\n",
    "    'MedFreq': {\n",
    "        'icache_thrash', \n",
    "        'pointer_chase'\n",
    "    },\n",
    "    'LowFreq': {\n",
    "        'mpi_bandwidth', \n",
    "        'mpi_barrier', \n",
    "        'spmv', \n",
    "        'stream'\n",
    "    }\n",
    "    }\n",
    "\n",
    "LABELS_EDP = {\n",
    "    'HighFreq': {\n",
    "        'atomic_fight',\n",
    "        'branch_mispredict',\n",
    "        'dgemm',\n",
    "        'fft_mix',\n",
    "        'icache_thrash',\n",
    "        'io_write',\n",
    "        'l3_stencil',\n",
    "        'mpi_barrier',\n",
    "    },\n",
    "    'MedFreq': {'pointer_chase'},\n",
    "    'LowFreq': {\n",
    "        'mpi_bandwidth', \n",
    "        'spmv', \n",
    "        'stream'\n",
    "    }\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_header(stdout_path: Path) -> Sequence[str]:\n",
    "    with stdout_path.open() as handle:\n",
    "        for line in handle:\n",
    "            if line.startswith('# GID|'):\n",
    "                parts = line.lstrip('#').strip().split('|')\n",
    "                fields = parts[3:]\n",
    "                if fields:\n",
    "                    return fields\n",
    "    raise RuntimeError(f'No LIKWID header found in {stdout_path}')\n",
    "\n",
    "\n",
    "def find_label(app: str, label_map: Dict[str, set[str]]) -> str:\n",
    "    for label, apps in label_map.items():\n",
    "        if app in apps:\n",
    "            return label\n",
    "    raise KeyError(f'No label mapping for app {app}')\n",
    "\n",
    "\n",
    "def iter_profile_rows(prof_path: Path) -> Iterable[List[str]]:\n",
    "    # print(f'Opening profile file: {prof_path}')\n",
    "    with prof_path.open() as handle:\n",
    "        in_loop = False\n",
    "        for raw_line in handle:\n",
    "            line = raw_line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            if line.startswith('LOOP_START_REL'):\n",
    "                in_loop = True\n",
    "                continue\n",
    "            if line.startswith('LOOP_END_REL'):\n",
    "                break\n",
    "            if not in_loop:\n",
    "                continue\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            yield line.split(',')\n",
    "\n",
    "\n",
    "def extract_metrics(row_parts: Sequence[str], header: Sequence[str]) -> Dict[str, float]:\n",
    "    metrics_count = int(row_parts[1])\n",
    "    cpu_count = int(row_parts[2])\n",
    "    values = [float(val) for val in row_parts[3:]]\n",
    "\n",
    "    metric_fields = list(header[1:])\n",
    "    if metrics_count != len(metric_fields):\n",
    "        raise ValueError(\n",
    "            f'Header mismatch: expected {len(metric_fields)} metrics, got {metrics_count}'\n",
    "        )\n",
    "\n",
    "    expected_values = 1 + metrics_count * cpu_count\n",
    "    if len(values) != expected_values:\n",
    "        raise ValueError(\n",
    "            f'Expected {expected_values} numeric entries, got {len(values)}'\n",
    "        )\n",
    "\n",
    "    metric_values = values[1:]\n",
    "    extracted: Dict[str, float] = {}\n",
    "    for idx, field in enumerate(metric_fields):\n",
    "        start = idx * cpu_count\n",
    "        end = start + cpu_count\n",
    "        segment = metric_values[start:end]\n",
    "        if not segment:\n",
    "            continue\n",
    "        extracted[field] = float(sum(segment) / len(segment))\n",
    "    return extracted\n",
    "\n",
    "\n",
    "def find_apps_dir(start: Path) -> Path:\n",
    "    current = start.resolve()\n",
    "    for _ in range(6):\n",
    "        candidate = current / 'apps'\n",
    "        if candidate.is_dir():\n",
    "            return candidate\n",
    "        if current.parent == current:\n",
    "            break\n",
    "        current = current.parent\n",
    "    raise FileNotFoundError('No apps directory found. Run from repo root or set apps_dir manually.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d7ff646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "apps_dir = find_apps_dir(Path.cwd())\n",
    "selected_freqs = ['1.5GHz', '1.8GHz','2.25GHz']\n",
    "group = 'dvfs'\n",
    "energy_out_path = Path('csv/training_dataset_dvfs_energy_labels.csv')\n",
    "edp_out_path = Path('csv/training_dataset_dvfs_edp_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "210ae065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21525,\n",
       " PosixPath('csv/training_dataset_dvfs_energy_labels.csv'),\n",
       " 21525,\n",
       " PosixPath('csv/training_dataset_dvfs_edp_labels.csv'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build datasets\n",
    "columns = ['label'] + FEATURE_FIELDS\n",
    "\n",
    "\n",
    "def build_dataset(label_map: Dict[str, set[str]], out_path: Path):\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    rows_written = 0\n",
    "    skipped_apps = []\n",
    "\n",
    "    with out_path.open('w', newline='') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=columns)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for app_dir in sorted(apps_dir.iterdir()):\n",
    "            if not app_dir.is_dir():\n",
    "                continue\n",
    "            app = app_dir.name\n",
    "            try:\n",
    "                label = find_label(app, label_map)\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "            for freq in selected_freqs:\n",
    "                stdout_path = app_dir / f'{app}_{group}_{freq}.out'\n",
    "                prof_path = app_dir / f'{app}_{group}_{freq}.prof'\n",
    "                if not stdout_path.exists() or not prof_path.exists():\n",
    "                    skipped_apps.append(f'{app}:{freq}')\n",
    "                    continue\n",
    "\n",
    "                header = parse_header(stdout_path)\n",
    "                missing = [f for f in FEATURE_FIELDS if f not in header]\n",
    "                if missing:\n",
    "                    skipped_apps.append(f'{app}:{freq}')\n",
    "                    continue\n",
    "\n",
    "                for parts in iter_profile_rows(prof_path):\n",
    "                    metrics = extract_metrics(parts, header)\n",
    "                    if any(field not in metrics for field in FEATURE_FIELDS):\n",
    "                        continue\n",
    "\n",
    "                    zero_metric_count = sum(1 for field in FEATURE_FIELDS if metrics.get(field, 0.0) == 0.0)\n",
    "                    if zero_metric_count >= 3:\n",
    "                        continue\n",
    "                    row = {\n",
    "                        'label': label,\n",
    "                    }\n",
    "                    for field in FEATURE_FIELDS:\n",
    "                        row[field] = metrics[field]\n",
    "                    writer.writerow(row)\n",
    "                    rows_written += 1\n",
    "\n",
    "    return rows_written, skipped_apps\n",
    "\n",
    "energy_rows, energy_skipped = build_dataset(LABELS_ENERGY, energy_out_path)\n",
    "edp_rows, edp_skipped = build_dataset(LABELS_EDP, edp_out_path)\n",
    "\n",
    "energy_rows, energy_out_path, edp_rows, edp_out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4755c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apps/frequencies skipped due to missing files or fields\n",
    "# sorted(set(skipped_apps))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
